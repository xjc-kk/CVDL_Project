{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# same as cycleGAN\n",
    "import os\n",
    "import numpy as np\n",
    "import math\n",
    "import itertools\n",
    "import datetime\n",
    "import time\n",
    "\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.utils import save_image, make_grid\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets\n",
    "from torch.autograd import Variable\n",
    "\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch\n",
    "\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "from PIL import Image\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "# build datast and dataloader\n",
    "class ImageDataset(Dataset):\n",
    "    def __init__(self, root, transforms_=None, mode=\"train\"):\n",
    "        self.transform = transforms.Compose(transforms_)\n",
    "#         self.unaligned = unaligned\n",
    "        if mode=='train':\n",
    "            self.files = glob.glob(\"edges2shoes/train/*.jpg\")\n",
    "        else:\n",
    "            self.files = glob.glob(\"edges2shoes/val/*.jpg\")\n",
    "    def __getitem__(self, index):\n",
    "        img = Image.open(self.files[index % len(self.files)])\n",
    "\n",
    "        # resize here\n",
    "#         print(image_A.size)\n",
    "        edges = img.crop((0,0,256, 256))\n",
    "        shoes = img.crop((256,0,512, 256))\n",
    "        #256*256\n",
    "        edges = self.transform(edges)\n",
    "        shoes = self.transform(shoes)\n",
    "        return {\"E\": edges, \"S\": shoes}\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.files)\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch\n",
    "\n",
    "def weights_init_normal(m):\n",
    "\n",
    "    classname = m.__class__.__name__\n",
    "\n",
    "    if classname.find(\"Conv\") != -1:\n",
    "\n",
    "        torch.nn.init.normal_(m.weight.data, 0.0, 0.02)\n",
    "\n",
    "    elif classname.find(\"BatchNorm2d\") != -1:\n",
    "\n",
    "        torch.nn.init.normal_(m.weight.data, 1.0, 0.02)\n",
    "\n",
    "        torch.nn.init.constant_(m.bias.data, 0.0)\n",
    "\n",
    "class UNetDown(nn.Module):\n",
    "\n",
    "    def __init__(self, in_size, out_size, normalize=True, dropout=0.0):\n",
    "\n",
    "        super(UNetDown, self).__init__()\n",
    "        layers = [nn.Conv2d(in_size, out_size, 4, 2, 1, bias=False)]\n",
    "        if normalize:\n",
    "            layers.append(nn.InstanceNorm2d(out_size))\n",
    "\n",
    "        layers.append(nn.LeakyReLU(0.2))\n",
    "\n",
    "        if dropout:\n",
    "\n",
    "            layers.append(nn.Dropout(dropout))\n",
    "\n",
    "        self.model = nn.Sequential(*layers)\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "class UNetUp(nn.Module):\n",
    "\n",
    "    def __init__(self, in_size, out_size, dropout=0.0):\n",
    "\n",
    "        super(UNetUp, self).__init__()\n",
    "\n",
    "        layers = [\n",
    "\n",
    "            nn.ConvTranspose2d(in_size, out_size, 4, 2, 1, bias=False),#反卷积\n",
    "\n",
    "            nn.InstanceNorm2d(out_size),\n",
    "\n",
    "            nn.ReLU(inplace=True),\n",
    "\n",
    "        ]\n",
    "\n",
    "        if dropout:\n",
    "\n",
    "            layers.append(nn.Dropout(dropout))\n",
    "\n",
    "        self.model = nn.Sequential(*layers)\n",
    "    def forward(self, x, skip_input):\n",
    "        x = self.model(x)\n",
    "        x = torch.cat((x, skip_input), 1)\n",
    "        return x\n",
    "\n",
    "class GeneratorUNet(nn.Module):\n",
    "    #dropout太大可能会出问题\n",
    "    def __init__(self, in_channels=3, out_channels=3):\n",
    "\n",
    "        super(GeneratorUNet, self).__init__()\n",
    "        self.down1 = UNetDown(in_channels, 64, normalize=False)\n",
    "\n",
    "        self.down2 = UNetDown(64, 128)\n",
    "\n",
    "        self.down3 = UNetDown(128, 256)\n",
    "\n",
    "        self.down4 = UNetDown(256, 512, dropout=0.5)\n",
    "\n",
    "#         self.down5 = UNetDown(512, 512, dropout=0.5)\n",
    "\n",
    "#         self.down6 = UNetDown(512, 512, dropout=0.5)\n",
    "\n",
    "        self.down7 = UNetDown(512, 512, dropout=0.5)\n",
    "\n",
    "        self.down8 = UNetDown(512, 512, normalize=False, dropout=0.5)\n",
    "\n",
    "        self.up1 = UNetUp(512, 512, dropout=0.5)\n",
    "\n",
    "#         self.up2 = UNetUp(1024, 512, dropout=0.5)\n",
    "\n",
    "#         self.up3 = UNetUp(1024, 512, dropout=0.5)\n",
    "\n",
    "        self.up4 = UNetUp(1024, 512, dropout=0.5)\n",
    "\n",
    "        self.up5 = UNetUp(1024, 256)\n",
    "\n",
    "        self.up6 = UNetUp(512, 128)\n",
    "\n",
    "        self.up7 = UNetUp(256, 64)\n",
    "        self.final = nn.Sequential(\n",
    "            nn.Upsample(scale_factor=2),\n",
    "            nn.ZeroPad2d((1, 0, 1, 0)),\n",
    "            nn.Conv2d(128, out_channels, 4, padding=1),\n",
    "            nn.Tanh(),\n",
    "\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        #256*256\n",
    "        # U-Net generator with skip connections from encoder to decoder\n",
    "        d1 = self.down1(x)\n",
    "        d2 = self.down2(d1)\n",
    "        d3 = self.down3(d2)\n",
    "        d4 = self.down4(d3)\n",
    "#         d5 = self.down5(d4)\n",
    "#         d6 = self.down6(d5)\n",
    "        d7 = self.down7(d4)\n",
    "        d8 = self.down8(d7)\n",
    "        u1 = self.up1(d8, d7)\n",
    "#         u2 = self.up2(u1, d6)\n",
    "#         u3 = self.up3(u2, d5)\n",
    "        u4 = self.up4(u1, d4)\n",
    "        u5 = self.up5(u4, d3)\n",
    "        u6 = self.up6(u5, d2)\n",
    "        u7 = self.up7(u6, d1)\n",
    "        return self.final(u7)\n",
    "\n",
    "class Discriminator(nn.Module):\n",
    "\n",
    "    def __init__(self, in_channels=3):\n",
    "\n",
    "        super(Discriminator, self).__init__()\n",
    "        def discriminator_block(in_filters, out_filters, normalization=True):\n",
    "\n",
    "            \"\"\"Returns downsampling layers of each discriminator block\"\"\"\n",
    "\n",
    "            layers = [nn.Conv2d(in_filters, out_filters, 4, stride=2, padding=1)]\n",
    "\n",
    "            if normalization:\n",
    "\n",
    "                layers.append(nn.InstanceNorm2d(out_filters))\n",
    "\n",
    "            layers.append(nn.LeakyReLU(0.2, inplace=True))\n",
    "\n",
    "            return layers\n",
    "        self.model = nn.Sequential(\n",
    "            *discriminator_block(in_channels * 2, 64, normalization=False),\n",
    "            *discriminator_block(64, 128),\n",
    "            *discriminator_block(128, 256),\n",
    "            *discriminator_block(256, 512),\n",
    "            nn.ZeroPad2d((1, 0, 1, 0)),\n",
    "\n",
    "            nn.Conv2d(512, 1, 4, padding=1, bias=False),\n",
    "            #modified here\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "    def forward(self, img_A, img_B):\n",
    "\n",
    "        # Concatenate image and condition image by channels to produce input\n",
    "        img_input = torch.cat((img_A, img_B), 1)#cat 2 input\n",
    "        return self.model(img_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda over\n"
     ]
    }
   ],
   "source": [
    "# import argparse\n",
    "import os\n",
    "import numpy as np\n",
    "import math\n",
    "import itertools\n",
    "import time\n",
    "import datetime\n",
    "import sys\n",
    "\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.utils import save_image\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets\n",
    "from torch.autograd import Variable\n",
    "\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch\n",
    "\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"7,4\"\n",
    "device_ids = [0,1]\n",
    "\n",
    "epoch=80\n",
    "n_epochs=80\n",
    "dataset_name=\"Generate_1\"\n",
    "batch_size=1024#改size啊...\n",
    "lr=0.0002\n",
    "b1=0.5\n",
    "b2=0.999\n",
    "decay_epoch=50\n",
    "# n_cpu=2\n",
    "sample_interval = 20\n",
    "checkpoint_interval=20\n",
    "img_height=64\n",
    "img_width=64\n",
    "channels=3\n",
    "\n",
    "os.makedirs(\"images_wg/%s\" %  dataset_name, exist_ok=True)\n",
    "os.makedirs(\"saved_models/%s\" %  dataset_name, exist_ok=True)\n",
    "\n",
    "cuda = True if torch.cuda.is_available() else False\n",
    "\n",
    "# Loss functions\n",
    "# criterion_G = torch.nn.MSELoss()\n",
    "criterion_D = torch.nn.BCELoss()\n",
    "\n",
    "\n",
    "criterion_pixelwise = torch.nn.L1Loss()\n",
    "\n",
    "# Loss weight of L1 pixel-wise loss between translated image and real image\n",
    "lambda_pixel = 100\n",
    "\n",
    "# Calculate output of image discriminator (PatchGAN)\n",
    "patch = (1,  img_height // 2 ** 4,  img_width // 2 ** 4)\n",
    "\n",
    "# Initialize generator and discriminator\n",
    "generator = GeneratorUNet()\n",
    "discriminator = Discriminator()\n",
    "\n",
    "if cuda:\n",
    "#     generator = generator.cuda()\n",
    "#     discriminator = discriminator.cuda()\n",
    "    \n",
    "    \n",
    "    generator = torch.nn.DataParallel(generator, device_ids=device_ids)\n",
    "    generator = generator.cuda(device=device_ids[0])\n",
    "    \n",
    "    discriminator = torch.nn.DataParallel(discriminator, device_ids=device_ids)\n",
    "    discriminator = discriminator.cuda(device=device_ids[0])\n",
    "    \n",
    "#     criterion_G.cuda()\n",
    "    criterion_D.cuda()\n",
    "    criterion_pixelwise.cuda()\n",
    "    print('cuda over')\n",
    "if  epoch != 0:\n",
    "    # Load pretrained models\n",
    "    generator.load_state_dict(torch.load(\"saved_models/%s/generator_%d.pth\" % ( dataset_name,  epoch)))\n",
    "    discriminator.load_state_dict(torch.load(\"saved_models/%s/discriminator_%d.pth\" % ( dataset_name,  epoch)))\n",
    "else:\n",
    "    # Initialize weights\n",
    "    generator.apply(weights_init_normal)\n",
    "    discriminator.apply(weights_init_normal)\n",
    "\n",
    "# Optimizers\n",
    "optimizer_G = torch.optim.Adam(generator.parameters(), lr= lr, betas=( b1,  b2))\n",
    "optimizer_D = torch.optim.Adam(discriminator.parameters(), lr= lr, betas=( b1,  b2))\n",
    "\n",
    "# Configure dataloaders\n",
    "transforms_ = [\n",
    "    transforms.Resize((img_height, img_width), Image.BICUBIC),\n",
    "    transforms.ToTensor(),\n",
    "#     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
    "]\n",
    "\n",
    "dataloader = DataLoader(\n",
    "    ImageDataset(\"%s\" %  dataset_name, transforms_=transforms_),\n",
    "    batch_size= batch_size,\n",
    "    shuffle=True,\n",
    "#     num_workers= n_cpu,\n",
    ")\n",
    "\n",
    "val_dataloader = DataLoader(\n",
    "    ImageDataset(\"%s\" %  dataset_name, transforms_=transforms_, mode=\"val\"),\n",
    "    batch_size=10,\n",
    "    shuffle=False,\n",
    "#     num_workers=1,\n",
    ")\n",
    "\n",
    "# Tensor type\n",
    "Tensor = torch.cuda.FloatTensor if cuda else torch.FloatTensor\n",
    "\n",
    "\n",
    "def sample_images(epoch):\n",
    "    \"\"\"Saves a generated sample from the validation set\"\"\"\n",
    "    imgs = next(iter(val_dataloader))\n",
    "    real_A = Variable(imgs[\"E\"].type(Tensor))\n",
    "    real_B = Variable(imgs[\"S\"].type(Tensor))\n",
    "    fake_B = generator(real_A)\n",
    "    img_sample = torch.cat((real_A.data, fake_B.data, real_B.data), -2)\n",
    "    save_image(img_sample, \"images_wg/%s/%s.png\" % ( dataset_name, epoch), nrow=5, normalize=True)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------\n",
    "#  Training\n",
    "# ----------\n",
    "\n",
    "prev_time = time.time()\n",
    "\n",
    "for epoch in range( epoch,  n_epochs):\n",
    "    for i, batch in enumerate(dataloader):\n",
    "\n",
    "        # Model inputs\n",
    "        real_A = Variable(batch[\"E\"].type(Tensor))\n",
    "        real_B = Variable(batch[\"S\"].type(Tensor))\n",
    "\n",
    "        # Adversarial ground truths\n",
    "        valid = Variable(Tensor(np.ones((real_A.size(0), *patch))), requires_grad=False)\n",
    "        fake = Variable(Tensor(np.zeros((real_A.size(0), *patch))), requires_grad=False)\n",
    "\n",
    "        # ------------------\n",
    "        #  Train Generators\n",
    "        # ------------------\n",
    "\n",
    "        optimizer_G.zero_grad()\n",
    "\n",
    "        # GAN loss E->S\n",
    "        fake_B = generator(real_A)\n",
    "#         pred_fake = discriminator(fake_B, real_A)\n",
    "        \n",
    "        G_loss = torch.mean(-discriminator(fake_B, real_A))\n",
    "        \n",
    "#         loss_GAN = criterion_D(pred_fake, valid)#\n",
    "        # Pixel-wise loss\n",
    "        loss_pixel = criterion_pixelwise(fake_B, real_B)\n",
    "\n",
    "        # Total loss\n",
    "#         loss_G = loss_GAN + lambda_pixel * loss_pixel\n",
    "        loss_G = G_loss + lambda_pixel * loss_pixel\n",
    "\n",
    "        loss_G.backward()\n",
    "\n",
    "        optimizer_G.step()\n",
    "\n",
    "        # ---------------------\n",
    "        #  Train Discriminator\n",
    "        # ---------------------\n",
    "\n",
    "        optimizer_D.zero_grad()\n",
    "\n",
    "        # Real loss\n",
    "        pred_real = discriminator(real_B, real_A)\n",
    "#         loss_real = criterion_D(pred_real, valid)\n",
    "\n",
    "        # Fake loss\n",
    "        pred_fake = discriminator(fake_B.detach(), real_A)\n",
    "#         loss_fake = criterion_D(pred_fake, fake)\n",
    "\n",
    "        # Total loss\n",
    "#         loss_D = 0.5 * (loss_real + loss_fake)\n",
    "        loss_D = torch.mean(pred_fake - pred_real)\n",
    "\n",
    "        loss_D.backward()\n",
    "        optimizer_D.step()\n",
    "\n",
    "        # --------------\n",
    "        #  Log Progress\n",
    "        # --------------\n",
    "\n",
    "        # Determine approximate time left\n",
    "        batches_done = epoch * len(dataloader) + i\n",
    "        batches_left =  n_epochs * len(dataloader) - batches_done\n",
    "        time_left = datetime.timedelta(seconds=batches_left * (time.time() - prev_time))\n",
    "        prev_time = time.time()\n",
    "\n",
    "        # Print log\n",
    "        sys.stdout.write(\n",
    "#             \"\\r[Epoch %d/%d] [Batch %d/%d] [D loss: %f] [G loss: %f, pixel: %f, adv: %f] ETA: %s\"\n",
    "            \"\\r[Epoch %d/%d] [Batch %d/%d] [D loss: %f] [G loss: %f, pixel: %f, ] ETA: %s\"\n",
    "            % (\n",
    "                epoch,\n",
    "                 n_epochs,\n",
    "                i,\n",
    "                len(dataloader),\n",
    "                loss_D.item(),\n",
    "                loss_G.item(),\n",
    "                loss_pixel.item(),\n",
    "#                 loss_GAN.item(),\n",
    "                time_left,\n",
    "            )\n",
    "        )\n",
    "\n",
    "        # If at sample interval save image\n",
    "#         if batches_done %  sample_interval == 0:\n",
    "#             sample_images(batches_done)\n",
    "\n",
    "    if  checkpoint_interval != -1 and epoch %  checkpoint_interval == 0:\n",
    "        # Save model checkpoints\n",
    "        torch.save(generator.state_dict(), \"saved_models/%s/generator_%d.pth\" % ( dataset_name, epoch))\n",
    "        torch.save(discriminator.state_dict(), \"saved_models/%s/discriminator_%d.pth\" % ( dataset_name, epoch))\n",
    "        sample_images(epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: out of memory (malloc at /opt/conda/conda-bld/pytorch_1579022027550/work/c10/cuda/CUDACachingAllocator.cpp:260)\nframe #0: c10::Error::Error(c10::SourceLocation, std::string const&) + 0x47 (0x7f968c826627 in /home1/lisl/anaconda3/envs/Pyt/lib/python3.8/site-packages/torch/lib/libc10.so)\nframe #1: <unknown function> + 0x1ea4a (0x7f968ca6aa4a in /home1/lisl/anaconda3/envs/Pyt/lib/python3.8/site-packages/torch/lib/libc10_cuda.so)\nframe #2: <unknown function> + 0x1ff2e (0x7f968ca6bf2e in /home1/lisl/anaconda3/envs/Pyt/lib/python3.8/site-packages/torch/lib/libc10_cuda.so)\nframe #3: THCStorage_resize + 0xa3 (0x7f96976476b3 in /home1/lisl/anaconda3/envs/Pyt/lib/python3.8/site-packages/torch/lib/libtorch.so)\nframe #4: at::native::empty_strided_cuda(c10::ArrayRef<long>, c10::ArrayRef<long>, c10::TensorOptions const&) + 0x626 (0x7f9698ff4f56 in /home1/lisl/anaconda3/envs/Pyt/lib/python3.8/site-packages/torch/lib/libtorch.so)\nframe #5: <unknown function> + 0x417bcea (0x7f9697558cea in /home1/lisl/anaconda3/envs/Pyt/lib/python3.8/site-packages/torch/lib/libtorch.so)\nframe #6: <unknown function> + 0x1b0ec41 (0x7f9694eebc41 in /home1/lisl/anaconda3/envs/Pyt/lib/python3.8/site-packages/torch/lib/libtorch.so)\nframe #7: <unknown function> + 0x366cf70 (0x7f9696a49f70 in /home1/lisl/anaconda3/envs/Pyt/lib/python3.8/site-packages/torch/lib/libtorch.so)\nframe #8: <unknown function> + 0x1b0ec41 (0x7f9694eebc41 in /home1/lisl/anaconda3/envs/Pyt/lib/python3.8/site-packages/torch/lib/libtorch.so)\nframe #9: <unknown function> + 0x187765e (0x7f9694c5465e in /home1/lisl/anaconda3/envs/Pyt/lib/python3.8/site-packages/torch/lib/libtorch.so)\nframe #10: at::native::to(at::Tensor const&, c10::TensorOptions const&, bool, bool, c10::optional<c10::MemoryFormat>) + 0x245 (0x7f9694c556b5 in /home1/lisl/anaconda3/envs/Pyt/lib/python3.8/site-packages/torch/lib/libtorch.so)\nframe #11: <unknown function> + 0x1bbcb5a (0x7f9694f99b5a in /home1/lisl/anaconda3/envs/Pyt/lib/python3.8/site-packages/torch/lib/libtorch.so)\nframe #12: <unknown function> + 0x38a2826 (0x7f9696c7f826 in /home1/lisl/anaconda3/envs/Pyt/lib/python3.8/site-packages/torch/lib/libtorch.so)\nframe #13: <unknown function> + 0x1c075a2 (0x7f9694fe45a2 in /home1/lisl/anaconda3/envs/Pyt/lib/python3.8/site-packages/torch/lib/libtorch.so)\nframe #14: torch::cuda::scatter(at::Tensor const&, c10::ArrayRef<long>, c10::optional<std::vector<long, std::allocator<long> > > const&, long, c10::optional<std::vector<c10::optional<c10::cuda::CUDAStream>, std::allocator<c10::optional<c10::cuda::CUDAStream> > > > const&) + 0x710 (0x7f9697952f20 in /home1/lisl/anaconda3/envs/Pyt/lib/python3.8/site-packages/torch/lib/libtorch.so)\nframe #15: <unknown function> + 0x9e6662 (0x7f96c3a31662 in /home1/lisl/anaconda3/envs/Pyt/lib/python3.8/site-packages/torch/lib/libtorch_python.so)\nframe #16: <unknown function> + 0x28b8a7 (0x7f96c32d68a7 in /home1/lisl/anaconda3/envs/Pyt/lib/python3.8/site-packages/torch/lib/libtorch_python.so)\nframe #17: PyCFunction_Call + 0x56 (0x562493c7a006 in /home1/lisl/anaconda3/envs/Pyt/bin/python)\nframe #18: _PyObject_MakeTpCall + 0x21f (0x562493c3b03f in /home1/lisl/anaconda3/envs/Pyt/bin/python)\nframe #19: _PyEval_EvalFrameDefault + 0x5307 (0x562493cdfd87 in /home1/lisl/anaconda3/envs/Pyt/bin/python)\nframe #20: _PyEval_EvalCodeWithName + 0x1dc (0x562493c85cec in /home1/lisl/anaconda3/envs/Pyt/bin/python)\nframe #21: _PyFunction_Vectorcall + 0x1c5 (0x562493c86da5 in /home1/lisl/anaconda3/envs/Pyt/bin/python)\nframe #22: _PyEval_EvalFrameDefault + 0x4d78 (0x562493cdf7f8 in /home1/lisl/anaconda3/envs/Pyt/bin/python)\nframe #23: _PyFunction_Vectorcall + 0xfb (0x562493c86cdb in /home1/lisl/anaconda3/envs/Pyt/bin/python)\nframe #24: PyVectorcall_Call + 0x6f (0x562493c3a86f in /home1/lisl/anaconda3/envs/Pyt/bin/python)\nframe #25: THPFunction_apply(_object*, _object*) + 0xb2f (0x7f96c36bfd1f in /home1/lisl/anaconda3/envs/Pyt/lib/python3.8/site-packages/torch/lib/libtorch_python.so)\nframe #26: PyCFunction_Call + 0xdb (0x562493c7a08b in /home1/lisl/anaconda3/envs/Pyt/bin/python)\nframe #27: _PyObject_MakeTpCall + 0x21f (0x562493c3b03f in /home1/lisl/anaconda3/envs/Pyt/bin/python)\nframe #28: _PyEval_EvalFrameDefault + 0x5307 (0x562493cdfd87 in /home1/lisl/anaconda3/envs/Pyt/bin/python)\nframe #29: _PyEval_EvalCodeWithName + 0x955 (0x562493c86465 in /home1/lisl/anaconda3/envs/Pyt/bin/python)\nframe #30: _PyFunction_Vectorcall + 0x21e (0x562493c86dfe in /home1/lisl/anaconda3/envs/Pyt/bin/python)\nframe #31: <unknown function> + 0x186a56 (0x562493c79a56 in /home1/lisl/anaconda3/envs/Pyt/bin/python)\nframe #32: PyIter_Next + 0xe (0x562493c3cc3e in /home1/lisl/anaconda3/envs/Pyt/bin/python)\nframe #33: PySequence_Tuple + 0xfb (0x562493c8513b in /home1/lisl/anaconda3/envs/Pyt/bin/python)\nframe #34: _PyEval_EvalFrameDefault + 0x5c1c (0x562493ce069c in /home1/lisl/anaconda3/envs/Pyt/bin/python)\nframe #35: _PyEval_EvalCodeWithName + 0x955 (0x562493c86465 in /home1/lisl/anaconda3/envs/Pyt/bin/python)\nframe #36: _PyFunction_Vectorcall + 0x21e (0x562493c86dfe in /home1/lisl/anaconda3/envs/Pyt/bin/python)\nframe #37: _PyEval_EvalFrameDefault + 0x6e4 (0x562493cdb164 in /home1/lisl/anaconda3/envs/Pyt/bin/python)\nframe #38: _PyEval_EvalCodeWithName + 0x955 (0x562493c86465 in /home1/lisl/anaconda3/envs/Pyt/bin/python)\nframe #39: _PyFunction_Vectorcall + 0x21e (0x562493c86dfe in /home1/lisl/anaconda3/envs/Pyt/bin/python)\nframe #40: _PyEval_EvalFrameDefault + 0x6e4 (0x562493cdb164 in /home1/lisl/anaconda3/envs/Pyt/bin/python)\nframe #41: _PyEval_EvalCodeWithName + 0x1dc (0x562493c85cec in /home1/lisl/anaconda3/envs/Pyt/bin/python)\nframe #42: _PyFunction_Vectorcall + 0x268 (0x562493c86e48 in /home1/lisl/anaconda3/envs/Pyt/bin/python)\nframe #43: _PyEval_EvalFrameDefault + 0x147b (0x562493cdbefb in /home1/lisl/anaconda3/envs/Pyt/bin/python)\nframe #44: _PyFunction_Vectorcall + 0xfb (0x562493c86cdb in /home1/lisl/anaconda3/envs/Pyt/bin/python)\nframe #45: <unknown function> + 0x16ff85 (0x562493c62f85 in /home1/lisl/anaconda3/envs/Pyt/bin/python)\nframe #46: _PyEval_EvalFrameDefault + 0x4d78 (0x562493cdf7f8 in /home1/lisl/anaconda3/envs/Pyt/bin/python)\nframe #47: _PyEval_EvalCodeWithName + 0x1dc (0x562493c85cec in /home1/lisl/anaconda3/envs/Pyt/bin/python)\nframe #48: _PyFunction_Vectorcall + 0x21e (0x562493c86dfe in /home1/lisl/anaconda3/envs/Pyt/bin/python)\nframe #49: <unknown function> + 0x17004b (0x562493c6304b in /home1/lisl/anaconda3/envs/Pyt/bin/python)\nframe #50: PyVectorcall_Call + 0x6f (0x562493c3a86f in /home1/lisl/anaconda3/envs/Pyt/bin/python)\nframe #51: _PyEval_EvalFrameDefault + 0x1f14 (0x562493cdc994 in /home1/lisl/anaconda3/envs/Pyt/bin/python)\nframe #52: _PyEval_EvalCodeWithName + 0x1dc (0x562493c85cec in /home1/lisl/anaconda3/envs/Pyt/bin/python)\nframe #53: _PyObject_FastCallDict + 0x1b8 (0x562493c87358 in /home1/lisl/anaconda3/envs/Pyt/bin/python)\nframe #54: _PyObject_Call_Prepend + 0x63 (0x562493c87623 in /home1/lisl/anaconda3/envs/Pyt/bin/python)\nframe #55: <unknown function> + 0x19472a (0x562493c8772a in /home1/lisl/anaconda3/envs/Pyt/bin/python)\nframe #56: _PyObject_MakeTpCall + 0x21f (0x562493c3b03f in /home1/lisl/anaconda3/envs/Pyt/bin/python)\nframe #57: _PyEval_EvalFrameDefault + 0x4cbd (0x562493cdf73d in /home1/lisl/anaconda3/envs/Pyt/bin/python)\nframe #58: _PyFunction_Vectorcall + 0xfb (0x562493c86cdb in /home1/lisl/anaconda3/envs/Pyt/bin/python)\nframe #59: _PyEval_EvalFrameDefault + 0x6e4 (0x562493cdb164 in /home1/lisl/anaconda3/envs/Pyt/bin/python)\nframe #60: _PyEval_EvalCodeWithName + 0x1dc (0x562493c85cec in /home1/lisl/anaconda3/envs/Pyt/bin/python)\nframe #61: PyEval_EvalCodeEx + 0x44 (0x562493c86ba4 in /home1/lisl/anaconda3/envs/Pyt/bin/python)\nframe #62: PyEval_EvalCode + 0x1c (0x562493c86bcc in /home1/lisl/anaconda3/envs/Pyt/bin/python)\nframe #63: <unknown function> + 0x206128 (0x562493cf9128 in /home1/lisl/anaconda3/envs/Pyt/bin/python)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-6f7261d4c326>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m101\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m111\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0msample_images\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-5-26ff9e15e5da>\u001b[0m in \u001b[0;36msample_images\u001b[0;34m(epoch)\u001b[0m\n\u001b[1;32m    119\u001b[0m     \u001b[0mreal_A\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimgs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"E\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m     \u001b[0mreal_B\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimgs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"S\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 121\u001b[0;31m     \u001b[0mfake_B\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenerator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreal_A\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    122\u001b[0m     \u001b[0mimg_sample\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreal_A\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfake_B\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreal_B\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    123\u001b[0m     \u001b[0msave_image\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_sample\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"images_wg/%s/%s.png\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m \u001b[0mdataset_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnrow\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnormalize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home1/lisl/anaconda3/envs/Pyt/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home1/lisl/anaconda3/envs/Pyt/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, *inputs, **kwargs)\u001b[0m\n\u001b[1;32m    146\u001b[0m                                    \"them on device: {}\".format(self.src_device_obj, t.device))\n\u001b[1;32m    147\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 148\u001b[0;31m         \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscatter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    149\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice_ids\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    150\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home1/lisl/anaconda3/envs/Pyt/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py\u001b[0m in \u001b[0;36mscatter\u001b[0;34m(self, inputs, kwargs, device_ids)\u001b[0m\n\u001b[1;32m    157\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    158\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mscatter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 159\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mscatter_kwargs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    160\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    161\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mparallel_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreplicas\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home1/lisl/anaconda3/envs/Pyt/lib/python3.8/site-packages/torch/nn/parallel/scatter_gather.py\u001b[0m in \u001b[0;36mscatter_kwargs\u001b[0;34m(inputs, kwargs, target_gpus, dim)\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mscatter_kwargs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_gpus\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m     \u001b[0;34mr\"\"\"Scatter with support for kwargs dictionary\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m     \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscatter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_gpus\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0minputs\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m     \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscatter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_gpus\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home1/lisl/anaconda3/envs/Pyt/lib/python3.8/site-packages/torch/nn/parallel/scatter_gather.py\u001b[0m in \u001b[0;36mscatter\u001b[0;34m(inputs, target_gpus, dim)\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[0;31m# None, clearing the cell\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m         \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscatter_map\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m         \u001b[0mscatter_map\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home1/lisl/anaconda3/envs/Pyt/lib/python3.8/site-packages/torch/nn/parallel/scatter_gather.py\u001b[0m in \u001b[0;36mscatter_map\u001b[0;34m(obj)\u001b[0m\n\u001b[1;32m     13\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mScatter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget_gpus\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscatter_map\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscatter_map\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home1/lisl/anaconda3/envs/Pyt/lib/python3.8/site-packages/torch/nn/parallel/scatter_gather.py\u001b[0m in \u001b[0;36mscatter_map\u001b[0;34m(obj)\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mscatter_map\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mScatter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget_gpus\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscatter_map\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home1/lisl/anaconda3/envs/Pyt/lib/python3.8/site-packages/torch/nn/parallel/_functions.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(ctx, target_gpus, chunk_sizes, dim, input)\u001b[0m\n\u001b[1;32m     87\u001b[0m             \u001b[0;31m# Perform CPU to GPU copies in a background stream\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m             \u001b[0mstreams\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0m_get_stream\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mdevice\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtarget_gpus\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 89\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcomm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscatter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_gpus\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchunk_sizes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstreams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     90\u001b[0m         \u001b[0;31m# Synchronize with the copy stream\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mstreams\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home1/lisl/anaconda3/envs/Pyt/lib/python3.8/site-packages/torch/cuda/comm.py\u001b[0m in \u001b[0;36mscatter\u001b[0;34m(tensor, devices, chunk_sizes, dim, streams)\u001b[0m\n\u001b[1;32m    145\u001b[0m         \u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mdevices\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    146\u001b[0m     \"\"\"\n\u001b[0;32m--> 147\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_scatter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevices\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchunk_sizes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstreams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    148\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA error: out of memory (malloc at /opt/conda/conda-bld/pytorch_1579022027550/work/c10/cuda/CUDACachingAllocator.cpp:260)\nframe #0: c10::Error::Error(c10::SourceLocation, std::string const&) + 0x47 (0x7f968c826627 in /home1/lisl/anaconda3/envs/Pyt/lib/python3.8/site-packages/torch/lib/libc10.so)\nframe #1: <unknown function> + 0x1ea4a (0x7f968ca6aa4a in /home1/lisl/anaconda3/envs/Pyt/lib/python3.8/site-packages/torch/lib/libc10_cuda.so)\nframe #2: <unknown function> + 0x1ff2e (0x7f968ca6bf2e in /home1/lisl/anaconda3/envs/Pyt/lib/python3.8/site-packages/torch/lib/libc10_cuda.so)\nframe #3: THCStorage_resize + 0xa3 (0x7f96976476b3 in /home1/lisl/anaconda3/envs/Pyt/lib/python3.8/site-packages/torch/lib/libtorch.so)\nframe #4: at::native::empty_strided_cuda(c10::ArrayRef<long>, c10::ArrayRef<long>, c10::TensorOptions const&) + 0x626 (0x7f9698ff4f56 in /home1/lisl/anaconda3/envs/Pyt/lib/python3.8/site-packages/torch/lib/libtorch.so)\nframe #5: <unknown function> + 0x417bcea (0x7f9697558cea in /home1/lisl/anaconda3/envs/Pyt/lib/python3.8/site-packages/torch/lib/libtorch.so)\nframe #6: <unknown function> + 0x1b0ec41 (0x7f9694eebc41 in /home1/lisl/anaconda3/envs/Pyt/lib/python3.8/site-packages/torch/lib/libtorch.so)\nframe #7: <unknown function> + 0x366cf70 (0x7f9696a49f70 in /home1/lisl/anaconda3/envs/Pyt/lib/python3.8/site-packages/torch/lib/libtorch.so)\nframe #8: <unknown function> + 0x1b0ec41 (0x7f9694eebc41 in /home1/lisl/anaconda3/envs/Pyt/lib/python3.8/site-packages/torch/lib/libtorch.so)\nframe #9: <unknown function> + 0x187765e (0x7f9694c5465e in /home1/lisl/anaconda3/envs/Pyt/lib/python3.8/site-packages/torch/lib/libtorch.so)\nframe #10: at::native::to(at::Tensor const&, c10::TensorOptions const&, bool, bool, c10::optional<c10::MemoryFormat>) + 0x245 (0x7f9694c556b5 in /home1/lisl/anaconda3/envs/Pyt/lib/python3.8/site-packages/torch/lib/libtorch.so)\nframe #11: <unknown function> + 0x1bbcb5a (0x7f9694f99b5a in /home1/lisl/anaconda3/envs/Pyt/lib/python3.8/site-packages/torch/lib/libtorch.so)\nframe #12: <unknown function> + 0x38a2826 (0x7f9696c7f826 in /home1/lisl/anaconda3/envs/Pyt/lib/python3.8/site-packages/torch/lib/libtorch.so)\nframe #13: <unknown function> + 0x1c075a2 (0x7f9694fe45a2 in /home1/lisl/anaconda3/envs/Pyt/lib/python3.8/site-packages/torch/lib/libtorch.so)\nframe #14: torch::cuda::scatter(at::Tensor const&, c10::ArrayRef<long>, c10::optional<std::vector<long, std::allocator<long> > > const&, long, c10::optional<std::vector<c10::optional<c10::cuda::CUDAStream>, std::allocator<c10::optional<c10::cuda::CUDAStream> > > > const&) + 0x710 (0x7f9697952f20 in /home1/lisl/anaconda3/envs/Pyt/lib/python3.8/site-packages/torch/lib/libtorch.so)\nframe #15: <unknown function> + 0x9e6662 (0x7f96c3a31662 in /home1/lisl/anaconda3/envs/Pyt/lib/python3.8/site-packages/torch/lib/libtorch_python.so)\nframe #16: <unknown function> + 0x28b8a7 (0x7f96c32d68a7 in /home1/lisl/anaconda3/envs/Pyt/lib/python3.8/site-packages/torch/lib/libtorch_python.so)\nframe #17: PyCFunction_Call + 0x56 (0x562493c7a006 in /home1/lisl/anaconda3/envs/Pyt/bin/python)\nframe #18: _PyObject_MakeTpCall + 0x21f (0x562493c3b03f in /home1/lisl/anaconda3/envs/Pyt/bin/python)\nframe #19: _PyEval_EvalFrameDefault + 0x5307 (0x562493cdfd87 in /home1/lisl/anaconda3/envs/Pyt/bin/python)\nframe #20: _PyEval_EvalCodeWithName + 0x1dc (0x562493c85cec in /home1/lisl/anaconda3/envs/Pyt/bin/python)\nframe #21: _PyFunction_Vectorcall + 0x1c5 (0x562493c86da5 in /home1/lisl/anaconda3/envs/Pyt/bin/python)\nframe #22: _PyEval_EvalFrameDefault + 0x4d78 (0x562493cdf7f8 in /home1/lisl/anaconda3/envs/Pyt/bin/python)\nframe #23: _PyFunction_Vectorcall + 0xfb (0x562493c86cdb in /home1/lisl/anaconda3/envs/Pyt/bin/python)\nframe #24: PyVectorcall_Call + 0x6f (0x562493c3a86f in /home1/lisl/anaconda3/envs/Pyt/bin/python)\nframe #25: THPFunction_apply(_object*, _object*) + 0xb2f (0x7f96c36bfd1f in /home1/lisl/anaconda3/envs/Pyt/lib/python3.8/site-packages/torch/lib/libtorch_python.so)\nframe #26: PyCFunction_Call + 0xdb (0x562493c7a08b in /home1/lisl/anaconda3/envs/Pyt/bin/python)\nframe #27: _PyObject_MakeTpCall + 0x21f (0x562493c3b03f in /home1/lisl/anaconda3/envs/Pyt/bin/python)\nframe #28: _PyEval_EvalFrameDefault + 0x5307 (0x562493cdfd87 in /home1/lisl/anaconda3/envs/Pyt/bin/python)\nframe #29: _PyEval_EvalCodeWithName + 0x955 (0x562493c86465 in /home1/lisl/anaconda3/envs/Pyt/bin/python)\nframe #30: _PyFunction_Vectorcall + 0x21e (0x562493c86dfe in /home1/lisl/anaconda3/envs/Pyt/bin/python)\nframe #31: <unknown function> + 0x186a56 (0x562493c79a56 in /home1/lisl/anaconda3/envs/Pyt/bin/python)\nframe #32: PyIter_Next + 0xe (0x562493c3cc3e in /home1/lisl/anaconda3/envs/Pyt/bin/python)\nframe #33: PySequence_Tuple + 0xfb (0x562493c8513b in /home1/lisl/anaconda3/envs/Pyt/bin/python)\nframe #34: _PyEval_EvalFrameDefault + 0x5c1c (0x562493ce069c in /home1/lisl/anaconda3/envs/Pyt/bin/python)\nframe #35: _PyEval_EvalCodeWithName + 0x955 (0x562493c86465 in /home1/lisl/anaconda3/envs/Pyt/bin/python)\nframe #36: _PyFunction_Vectorcall + 0x21e (0x562493c86dfe in /home1/lisl/anaconda3/envs/Pyt/bin/python)\nframe #37: _PyEval_EvalFrameDefault + 0x6e4 (0x562493cdb164 in /home1/lisl/anaconda3/envs/Pyt/bin/python)\nframe #38: _PyEval_EvalCodeWithName + 0x955 (0x562493c86465 in /home1/lisl/anaconda3/envs/Pyt/bin/python)\nframe #39: _PyFunction_Vectorcall + 0x21e (0x562493c86dfe in /home1/lisl/anaconda3/envs/Pyt/bin/python)\nframe #40: _PyEval_EvalFrameDefault + 0x6e4 (0x562493cdb164 in /home1/lisl/anaconda3/envs/Pyt/bin/python)\nframe #41: _PyEval_EvalCodeWithName + 0x1dc (0x562493c85cec in /home1/lisl/anaconda3/envs/Pyt/bin/python)\nframe #42: _PyFunction_Vectorcall + 0x268 (0x562493c86e48 in /home1/lisl/anaconda3/envs/Pyt/bin/python)\nframe #43: _PyEval_EvalFrameDefault + 0x147b (0x562493cdbefb in /home1/lisl/anaconda3/envs/Pyt/bin/python)\nframe #44: _PyFunction_Vectorcall + 0xfb (0x562493c86cdb in /home1/lisl/anaconda3/envs/Pyt/bin/python)\nframe #45: <unknown function> + 0x16ff85 (0x562493c62f85 in /home1/lisl/anaconda3/envs/Pyt/bin/python)\nframe #46: _PyEval_EvalFrameDefault + 0x4d78 (0x562493cdf7f8 in /home1/lisl/anaconda3/envs/Pyt/bin/python)\nframe #47: _PyEval_EvalCodeWithName + 0x1dc (0x562493c85cec in /home1/lisl/anaconda3/envs/Pyt/bin/python)\nframe #48: _PyFunction_Vectorcall + 0x21e (0x562493c86dfe in /home1/lisl/anaconda3/envs/Pyt/bin/python)\nframe #49: <unknown function> + 0x17004b (0x562493c6304b in /home1/lisl/anaconda3/envs/Pyt/bin/python)\nframe #50: PyVectorcall_Call + 0x6f (0x562493c3a86f in /home1/lisl/anaconda3/envs/Pyt/bin/python)\nframe #51: _PyEval_EvalFrameDefault + 0x1f14 (0x562493cdc994 in /home1/lisl/anaconda3/envs/Pyt/bin/python)\nframe #52: _PyEval_EvalCodeWithName + 0x1dc (0x562493c85cec in /home1/lisl/anaconda3/envs/Pyt/bin/python)\nframe #53: _PyObject_FastCallDict + 0x1b8 (0x562493c87358 in /home1/lisl/anaconda3/envs/Pyt/bin/python)\nframe #54: _PyObject_Call_Prepend + 0x63 (0x562493c87623 in /home1/lisl/anaconda3/envs/Pyt/bin/python)\nframe #55: <unknown function> + 0x19472a (0x562493c8772a in /home1/lisl/anaconda3/envs/Pyt/bin/python)\nframe #56: _PyObject_MakeTpCall + 0x21f (0x562493c3b03f in /home1/lisl/anaconda3/envs/Pyt/bin/python)\nframe #57: _PyEval_EvalFrameDefault + 0x4cbd (0x562493cdf73d in /home1/lisl/anaconda3/envs/Pyt/bin/python)\nframe #58: _PyFunction_Vectorcall + 0xfb (0x562493c86cdb in /home1/lisl/anaconda3/envs/Pyt/bin/python)\nframe #59: _PyEval_EvalFrameDefault + 0x6e4 (0x562493cdb164 in /home1/lisl/anaconda3/envs/Pyt/bin/python)\nframe #60: _PyEval_EvalCodeWithName + 0x1dc (0x562493c85cec in /home1/lisl/anaconda3/envs/Pyt/bin/python)\nframe #61: PyEval_EvalCodeEx + 0x44 (0x562493c86ba4 in /home1/lisl/anaconda3/envs/Pyt/bin/python)\nframe #62: PyEval_EvalCode + 0x1c (0x562493c86bcc in /home1/lisl/anaconda3/envs/Pyt/bin/python)\nframe #63: <unknown function> + 0x206128 (0x562493cf9128 in /home1/lisl/anaconda3/envs/Pyt/bin/python)\n"
     ]
    }
   ],
   "source": [
    "for i in range(101,111):\n",
    "    sample_images(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
